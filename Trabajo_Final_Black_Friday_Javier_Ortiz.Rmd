---
title: "Trabajo Final Black Friday"
author: "Javier Ortiz Montenegro"
date: "11 de enero de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Se cargan las diversas librerías necesarias.

```{r warning = F, message = F}
library(tidyverse)
library(webshot)
library(GGally)
library(recommenderlab)
library(caret)
```

Lo primero a la hora de tratar los datos será su carga, comprobación, limpieza de NAs, y transformación de las variables a formatos optimos.

```{r}
bf.df = read_csv("BlackFriday.csv") #Se cargan directamente los datos en una tibble
bf.df %>% summary() #Se comprueban los datos que contiene para saber como tratarlos
bf.df %>% str()
bf.df %>% head() 
bf.df %>% tail()
bf.df = mutate(bf.df[,-c(10:11)]) %>% na.omit %>% droplevels() #Se eliminan NAs (Especialmente concentrados en las columnas Product_Category 2 y 3)
bf.df = bf.df[!duplicated(bf.df),] #Se eliminan duplicados en caso de haberlos
bf.df$User_ID = bf.df$User_ID - 1000000 #Se convierten User_ID en números del 1 al 6040
bf.df$User_ID = as.factor(bf.df$User_ID) #Se transforman a factor los datos que se considera oportuno
bf.df$Product_ID = as.factor(bf.df$Product_ID) 
bf.df$Gender = as.factor(bf.df$Gender)
bf.df$Age = as.factor(bf.df$Age)
bf.df$City_Category = as.factor(bf.df$City_Category)
bf.df$Marital_Status = as.factor(bf.df$Marital_Status)
bf.df$Stay_In_Current_City_Years = as.factor(bf.df$Stay_In_Current_City_Years)
bf.df$Product_Category_1 = as.factor(bf.df$Product_Category_1)
bf.df$Occupation = as.factor(bf.df$Occupation)
bf.df %>% summary() #De nuevo se comprueban los datos para confirmar que ya estén "limpios"
bf.df %>% str()
```

Se integra una gráfica dinámica mediante shiny para realizar los cruces basicos del gasto y orientar hacia estudios interesantes de los datos.

```{r}
#En mi pc tarda un poco en cargar los gráficos. Espero que con un procesador más potente sea más fluido.
#knitr::include_app("http://127.0.0.1:4231", height = 750)
```

Es digno de mención el hecho de que la categoría de producto con mayor gasto es la 1 y sin embargo en unidades este puesto pertenece a la categoría 5 (Como se puede comprobar al realizar el summary).

```{r}
bf.df %>%  ggplot(aes(x = Product_Category_1, y = Purchase, color = Product_Category_1)) + geom_boxplot(show.legend = F) + xlab("Categoría de producto") + ylab("Gasto") + ggtitle("Gasto por categoría de producto") + theme(plot.title = element_text(hjust = 0.5))
```

En este boxplot se puede comprobar como las categorías que más han vendido en el black friday no son productos que pertenezcan a una categoría de lujo (La categoría 1 es más cara que la 5 y la 8, pero aún así sería discutible catalogar dicha categoría como articulos de lujo).


Compras hombres vs compra mujeres por categorías, 

```{r}
bf.df %>% ggplot(aes(x = Product_Category_1, y = Purchase, color = Age)) + geom_bar(show.legend = T, stat = "identity") + xlab("Categoría de producto") + ylab("Gasto") + ggtitle("Gasto por categoría de producto mujeres frente a hombres") + facet_wrap(~ Gender) + theme(plot.title = element_text(hjust = 0.5))
```

Como se pude comprobar practicamente todas las categorías tienen un gasto mayor cuando el genero es hombre, no obstante, el mayor aumento con diferencia es en la categoría producto 1, lo cual hace pensar que es una categoría especialmente atractiva para el cliente masculino.

El siguiente gráfico es una combinación de distintos cruces entre variables, los colores corresponden de la siguiente manera: Rojo = Mujer, Azul = hombre.

```{r message = F}
bfcant.df = bf.df %>% group_by(User_ID) %>% summarise(Gender = Gender[1],Age = Age[1],Occupation = Occupation[1], City_Category = City_Category[1], Stay_In_Current_City_Years = Stay_In_Current_City_Years[1], Marital_Status = Marital_Status[1], Item_Count = n()) 
#Se juntan los compradores para no desvirtuar los resultados de las próximas graficas al cruzar variables factor entre ellas ya que de no ser así se contabilizarían de forma multiple los usuarios con más de una compra.
ggpairs(bfcant.df[,c(5:8)], cardinality_threshold = 21, aes(color = bfcant.df$Gender, alpha = 0.5))
```

Las gráficas no muestran mucha información nueva, la mayoría de la información que ya se había podido visualizar en la gráfica interactiva.

Una vez comprobados los datos y tras realizar un análisis por encima de los mismos se puede confirmar que si una empresa decidiera entrar en el mercado la recomendación sería fabricar productos de la categoría 1, y tener una inversión en marketing especialmente dedicada a hombres entre 26 y 35 años, soltero, que resida desde hace un año en una ciudad de categoría B, y que se dedique a la profesión 0, 4 ó 7.

Para profundizar más podría realizar una predicción de las ventas en caso de pretender vender unicamente a ese objetivo y dedicarse a la categoría de producto 1, o realizar una clasificación de la edad de un comprador según el resto de variables, pero este tipo de modelos ya los he realizado en otras asignaturas.
Por lo tanto me decantaré por un sistema de recomendación, modelo que aún no he trabajado y que también tiene sentido con estos datos.

Se comienza con el tratamiento de los datos convirtiendo el data frame original en una matriz binaria que recoja el ID del usuario y los productos comprados. De esta manera se podrá utilizar el paquete recommenderlab para realizar el modelo y predicción de las recomendaciones.

```{r}
#Se transforma el data frame pasando cada factor de la columna Product_ID a una variable propia con el ID del producto y de esta manera transformar el data frame en una matriz binaria con 0 en caso de no haber comprado el producto y 1 en caso de si haberlo comprado.
bfcant.df = bf.df %>%
  gather(observation, Val, Product_ID) %>%
  group_by(User_ID,observation, Val) %>%
  summarise(n= n()) %>%
  ungroup() %>%
  spread(Val, n, fill=0)

#Se eliminan las columnas 1 y 2 que corresponden a User_ID (ya recogido en el índice) y a una columna que recoge "Product_ID" ya que es el nombre de la columna original.
bfcant.df = bfcant.df[,-c(1,2)]

#Por ultimo se transforma el data frame en una binaryRatingMatrix para poder trabajar y entrenar el modelo.
bf.bin = data.matrix(bfcant.df)
bf.bin = as(bf.bin, "binaryRatingMatrix")
```

Una vez tratados los datos se pasa al entrenamiento y predicción del modelo de recomendación, inicialmente se realizará una evaluación mediante validación cruzada para, de esta manera, seleccionar el mejor modelo de recomendación. Una vez seleccionado el modelo que mejor se adapte a las necesidades se construirá un modelo hibrido para que un porcentaje de las recomendaciones salgan de la "zona de confort" del usuario.

```{r}
set.seed(2019)

#Seleccion de usuarios con al menos 40 compras y productos comprados como mínimo 80 veces.
bf.bin = bf.bin[rowCounts(bf.bin) > 40,
                colCounts(bf.bin) > 80]

#Se usa validación cruzada para validar las recomendaciones.
eval_sets = evaluationScheme(data = bf.bin,
                             method = "cross-validation",
                             k = 5,
                             given = 20)

#Los modelos a comparar son basados en usuarios, basados en items (mediante distintos metodos), y por ultimo un modelo aleatorio.
modelos = list(IBCF.cos = list(name = "IBCF", params = list(method = "cosine")),
               IBCF.cor = list(name = "IBCF", params = list(method = "pearson")),
               IBCF.jac = list(name = "IBCF", params = list(method = "Jaccard")),
               UBCF.cos = list(name = "UBCF", params = list(method = "cosine")),
               UBCF.cor = list(name = "UBCF", params = list(method = "pearson")),
               UBCF.jac = list(name = "UBCF", params = list(method = "Jaccard")),
               random = list(name = "RANDOM", params = NULL))

resul = evaluate(x = eval_sets,
                 method = modelos,
                 n = c(1:7, seq(10,100,10)))
```

Se comprueban los resultados de la validación cruzada mediante gráficos.

```{r}
plot(resul, annotate = 1, legend = "topleft") + title("Curva AUC")
```

Este primer gráfico muestra el ratio de verdaderos positivos, en el eje de ordenadas, frente al ratio de falsos positivos, en el eje de abscisas.
Se puede extraer de dicho gráfico que los modelos basados en usuarios tienen un mejor ratio de verdaderos positivos frente a falsos.

```{r}
plot(resul, "prec/rec", annotate = 1, legend = "bottomright") + title("Precisión vs Eficacia")
```

En este caso, el gráfico cruza precisión contra eficacia se puede observar como el metodo de Jaccard produce mejores resultados con pocas recomendaciones y como el la intención es que se recomienden unos 10 productos dicho metodo es el apropiado.

Se procede a una evaluación individual del modelo orientado a usuarios con Jaccard en mayor profundidad.

```{r}
res.jac = evaluate(x = eval_sets,
                 method = "UBCF", parameter = list(method = "Jaccard"),
                 n = seq(10,100,10))
getConfusionMatrix(res.jac)[[1]]
plot(res.jac, "prec/rec", annotate = T, main = "Precisión vs Eficacia (UBFC Jaccard)")
```

En la tabla hay datos interesantes sobre el modelo como son la precisión, el recall (eficacia), así como los ratios de verdaderos positivos y falsos positivos.

No obstante, la precisión y la eficacia se interpretan con mayor facilidad en la tabla, con 10 recomendaciones la precisión (porcentaje de veces que el modelo recomienda un producto que realmente es comprado frente al total de recomendaciones realizadas) es del `r round(getConfusionMatrix(res.jac)[[1]][1,5] * 100, 2)`%. Lo que significa que si nos basamos en los resultados de esta evaluación si recomendamos 10 productos a cada usuario este considerará de su interés entre 3 y 4 de ellos.
Por otro lado, la eficacia o recall (porcentaje de productos interesantes recomendados por el modelo sobre el total de productos interesantes para el usuario) es del `r round(getConfusionMatrix(res.jac)[[1]][1,6] * 100, 2)`%. No es de extrañar que el porcentaje sea tan bajo ya que unicamente se estan recomendando 10 productos, que con 10 productos se cubra el `r round(getConfusionMatrix(res.jac)[[1]][1,6] * 100, 2)`% del total de productos interesantes para un usuario parece ser más que decente.

Una vez evaluado el modelo y comprobado que es el que mejor se adapata se procede a crear un modelo hibrido que recomiende 12 productos, 10 serán en base a usuario y 2 de manera aleatoria para que exista la posibilidad de que pase a productos nuevos que quizá no conocía.

```{r}
#Se separan los datos en dos grupos, uno de entrenamiento y otro de prueba.
sep = sample(x= c(T, F),
             size = nrow(bf.bin),
             replace = T,
             prob = c(0.8, 0.2))

train = bf.bin[sep,]
test = bf.bin[!sep,]

#Se entrena el modelo con el subconjunto de entrenamiento.
recom_hibrida = HybridRecommender(
  Recommender(train, method = "UBCF", parameter = list(method = "Jaccard")),
  Recommender(train, method = "RANDOM"),
  weights = c(0.85, 0.15))

#Se procede a la predicción con el subconjunto de prueba.
pred = predict(object = recom_hibrida, newdata = test, n = 12)
rec.matrix = sapply(pred@items, function(x){
                            colnames(bf.bin[,x])
  })

#Se muestran 12 recomendaciones para los 5 primeros usuarios, de esta manera comprobamos que funcione correctamente.
rec.matrix[,1:5]
```

La matriz muestra las 12 recomendaciones del modelo hibrido para los 5 primeros usuarios del subconjunto de prueba. De esas 12 recomendaciones 10 son basadas en el usuario y 2 aleatorias.
Sería mucho más interesante si se supiera que producto es el recomiendado, desafortunadamente la base de datos no lo especifica, unicamente muestra su código.